{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create PDF of Video File (Images and Transcript)\n",
    "\n",
    "## Overview\n",
    "\n",
    "Users in many cases need to import video fales into the RAG (Retrieval and Augmentation) but first need to convert the video file into a format that can be ingested into the RAG.\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "RAG solutions such as AWS Bedrock only support certain file formats when importing documents. Furthermore, embed models do not understand video files natively. Users need to convert video files into formats compatible with the embed models.\n",
    "\n",
    "> Note: it's important to use an embed model that is multimodal, i.e. that they understand both images and text.\n",
    "\n",
    "## Solution\n",
    "\n",
    "The (current) best approach is to create a PDF that has images and text extracted from the video file. The PDF is the recommended format since it can have both images and text. Also, a wide variety of RAG solutions support ingesting PDF files.\n",
    "\n",
    "This notebook's code helps users:\n",
    "\n",
    "1. Load video files\n",
    "2. Extract audio from the video files\n",
    "3. Transcribe the audio as text\n",
    "4. Create images from the video file\n",
    "5. Create a PDF that combines the images and audio transcription"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Audio from Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy import VideoFileClip\n",
    "\n",
    "\n",
    "# Define file paths\n",
    "audio_path = \"output/audio/output_audio.wav\"\n",
    "frame_path = \"output/frame\"\n",
    "pdf_path = \"output/pdf/output_pdf.pdf\"\n",
    "transcript_path = \"output/transcript/output_audio_transcript.txt\"\n",
    "video_path = \"input/video/activity_editor_overview.mp4\"\n",
    "\n",
    "\n",
    "# Load the video file\n",
    "video = VideoFileClip(video_path)\n",
    "\n",
    "# Extract and save the audio\n",
    "audio = video.audio\n",
    "audio.write_audiofile(audio_path)\n",
    "\n",
    "video.close()\n",
    "\n",
    "print(f\"Audio saved to {audio_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcribe Audio to Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "\n",
    "\n",
    "# Load the Whisper model\n",
    "model = whisper.load_model(\"base\")\n",
    "\n",
    "# Transcribe the audio file\n",
    "result = model.transcribe(audio_path)\n",
    "\n",
    "# Access the transcribed text\n",
    "transcript = result['text']\n",
    "\n",
    "# Save the transcription to a file\n",
    "with open(transcript_path, \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(transcript)\n",
    "\n",
    "print(f\"Transcription saved to {transcript_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Images from the Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "frame_rate = cap.get(cv2.CAP_PROP_FPS)  # Get the frame rate\n",
    "interval = int(frame_rate)  # Capture one frame per second\n",
    "\n",
    "frame_count = 0\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    if frame_count % interval == 0:\n",
    "        frame_name = f\"{frame_path}/frame_{frame_count // interval:04d}.jpg\"\n",
    "        cv2.imwrite(frame_name, frame)\n",
    "        print(f\"Creating frame {frame_name}\")\n",
    "    frame_count += 1\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create PDF with Images and Transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF saved to output/pdf/output_pdf.pdf\n"
     ]
    }
   ],
   "source": [
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Image, Spacer\n",
    "from reportlab.lib.styles import getSampleStyleSheet\n",
    "from reportlab.lib.units import inch\n",
    "import os\n",
    "\n",
    "\n",
    "def create_pdf_with_transcript_and_images(transcript_path, frames_path, pdf_path):\n",
    "    # Read the transcript\n",
    "    with open(transcript_path, 'r') as file:\n",
    "        transcript = file.read()\n",
    "\n",
    "    # Create a PDF document\n",
    "    doc = SimpleDocTemplate(pdf_path, pagesize=letter)\n",
    "    elements = []\n",
    "\n",
    "    # Get a sample style sheet\n",
    "    styles = getSampleStyleSheet()\n",
    "    normal_style = styles['Normal']\n",
    "\n",
    "    # Load frames\n",
    "    frame_files = sorted(f for f in os.listdir(frames_path) if f.endswith('.jpg'))\n",
    "\n",
    "    # Split transcript into segments for each frame\n",
    "    transcript_lines = transcript.split('\\n')\n",
    "    lines_per_frame = len(transcript_lines) // len(frame_files) + 1\n",
    "\n",
    "    for i, frame_file in enumerate(frame_files):\n",
    "        frame_path = os.path.join(frames_path, frame_file)\n",
    "        img = Image(frame_path)\n",
    "        img.drawHeight = 3 * inch\n",
    "        img.drawWidth = 4 * inch\n",
    "        elements.append(img)\n",
    "        elements.append(Spacer(1, 12))\n",
    "\n",
    "        # Add corresponding transcript segment\n",
    "        start_line = i * lines_per_frame\n",
    "        end_line = start_line + lines_per_frame\n",
    "        segment = '\\n'.join(transcript_lines[start_line:end_line])\n",
    "        para = Paragraph(segment, normal_style)\n",
    "        elements.append(para)\n",
    "        elements.append(Spacer(1, 12))\n",
    "\n",
    "    # Build the PDF document\n",
    "    doc.build(elements)\n",
    "\n",
    "create_pdf_with_transcript_and_images(transcript_path, frame_path, pdf_path)\n",
    "\n",
    "print(f\"PDF saved to {pdf_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
